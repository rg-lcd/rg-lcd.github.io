<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="We proposed Reward Guided Latent Consistency Distillation.">
  <meta name="keywords" content=" Text-to-Image, Consistency Model, Learning from Human/AI Feedback">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Reward Guided Latent Consistency Distillation
  </title>
  <!-- custom fonts -->
  <link rel="stylesheet" type="text/css"
    href="https://cdn.rawgit.com/dreampulse/computer-modern-web-font/master/fonts.css">
  <link href="https://fonts.cdnfonts.com/css/proxima-nova-2" rel="stylesheet">
  <!-- end custom fonts -->

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" type="svg" href="./static/fire.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Reward Guided Latent Consistency Distillation
            </h1>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://sites.google.com/view/jiachenli/home">Jiachen Li</a><sup>1</sup>
              </span>
              <span class="author-block">
                <a href="https://weixi-feng.github.io/">Weixi Feng</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://wenhuchen.github.io//">Wenhu Chen</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://sites.cs.ucsb.edu/~william/">William Yang Wang</a><sup>1</sup>
              </span>
            </div>


            <div class="is-size-5 publication-authors" style="margin-top: 15px;">
              <span class="author-block"><sup>1</sup>UC Santa Barbara,</span>
              <span class="author-block"><sup>2</sup>University of Waterloo,</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a target="_blank" href="https://proceedings.mlr.press/v202/li23av/li23av.pdf" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a target="_blank" href="https://arxiv.org/abs/2211.15956"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a target="_blank" href="https://github.com/cfpi-icml23/cfpi"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <!-- <span class="link-block">
                  <a target="_blank" href="https://github.com/google/nerfies/releases/tag/0.1"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>
                </span> -->
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <img src="./static/images/teaser-sd-2-1-base-horizontal.jpg" alt="" srcset="">
        <h2 class="subtitle has-text-centered">
          <span class="dnerf"> Generation of our RG-LCM (<a href="https://github.com/tgxs002/HPSv2/tree/master" target="_blank">HPSv2.1</a>) distilled from <a href="https://huggingface.co/stabilityai/stable-diffusion-2-1-base" target="_blank">Stable Diffusion v2-1-base</a> </span>
        </h2>
      </div>
      <div class="hero-body">
        <img src="./static/images/teaser-4p.jpg" alt="" srcset="">
        <h2 class="subtitle has-text-centered">
          <span class="dnerf">Closed-form policy improvement operators</span> enable stable offline policy improvement.
        </h2>
      </div>
    </div>
  </section>

  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <img src="./static/images/beautiful_oil.png" style="width: auto;" alt="">j
          </div>
          <div class="item">
            <img src="./static/images/girl.png" style="width: auto;" alt="">j
          </div>
          <div class="item">
            <img src="./static/images/unicorn.png" style="width: auto;" alt="">
          </div>
          <div class="item">
            <img src="./static/images/tea_cup.png" style="width: auto;" alt="">
          </div>
          <div class="item">
            <img src="./static/images/sculpture.png" style="width: auto;" alt="">
          </div>
          <div class="item">
            <img src="./static/images/pirate_ship.png" style="width: auto;" alt="">
          </div>
        </div>
      </div>
    </div>

  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Latent Consistency Distillation (LCD) has emerged as a promising paradigm for efficient text-to-image synthesis.
              By distilling a latent consistency model (LCM) from a pre-trained teacher latent diffusion model (LDM),
              LCD facilitates the generation of high-fidelity images within merely 2 to 4 inference steps.
              However, the LCM's efficient inference is obtained at the cost of the sample quality.
              In this paper, we propose compensating the quality loss by aligning LCM's output with human preference during training.
              Specifically, we introduce Reward Guided LCD (RG-LCD), which integrates feedback from a reward model (RM) into the LCD
              process by augmenting the original LCD loss with the objective of maximizing the reward associated with LCM's single-step generation.
              As validated through human evaluation, when trained with the feedback of a good RM,
              the 2-step generations from our RG-LCM are favored by humans over the 50-step DDIM samples from the teacher LDM,
              representing a 25 times inference acceleration without quality loss.
            </p>
            <p>
            As directly optimizing towards differentiable RMs can suffer from over-optimization,
            we overcome this difficulty by proposing the use of a latent proxy RM (LRM).
            This novel component serves as an intermediary, connecting our LCM with the RM.
            Empirically, we demonstrate that incorporating the LRM into our RG-LCD successfully avoids high-frequency noise in the generated images,
            contributing to both improved FID on MS-COCO and a higher HPSv2.1 score on HPSv2's test set, surpassing those achieved by the baseline LCM.
          </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">

      <!-- Training Pipeline. -->
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Overview of Training Pipeline</h2>

          <img src="./static/images/rg-lcd-framework.jpg" alt="" srcset="">
          <div class="content has-text-justified">
            <p>
              Our RG-LCD framework consists of three main components: a teacher LDM, a student LCM, and a Reward Model (RM).
              The teacher LDM is pre-trained on a large-scale dataset and serves as the source of the ground-truth latent codes.
              The student LCM is trained to mimic the teacher LDM's generation process by distilling the teacher's latent codes.
              During training, the LCM is optimized to maximize the reward predicted by the RM.
            </p>
          </div>
        </div>
      </div>
      <!--/ Training Pipeline. -->

      <div class="container is-max-desktop">

        <!-- Acknowledgement. -->
        <div class="columns is-centered">
          <div class="column is-full-width">
            <h2 class="title is-3">Acknowledgement</h2>

            <div class="content has-text-justified">
              <p>
                This project would not be possible without the following wonderful prior work.
              </p>

              <p>
                <a href="https://github.com/luosiallen/latent-consistency-model">Latent Consistency Model</a> gave inspiration to our
                method,
                <a href="https://github.com/tgxs002/HPSv2">HPSv2.1</a>
                provides great reward models, and
                <a href="https://github.com/huggingface/diffusers/">DiffusersðŸ§¨</a> offered a strong diffusion model training framework
                for building our code from.
              </p>
            </div>
          </div>
        </div>
        <!--/ Acknowledgement. -->
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{li2024rglcd,
  title={Reward Guided Latent Consistency Distillation},
  author={Jiachen Li and Weixi Feng and Wenhu Chen and William Yang Wang},
  journal={ARXIV},
  year={2024}
}
      </code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="https://proceedings.mlr.press/v202/li23av/li23av.pdf">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/cfpo-icml23/cfpi" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p style="text-align: center
              ">
              Website templated borrowed from <a href="https://github.com/nerfies/nerfies.github.io">nerfies.</a>
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>


</body>

</html>